{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Assignment: Рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать **recall@k** и **precision@k**.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "### Входные данные\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - **id**-шниками просмотренных и **id**-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: **id** просмотренных товаров через **,** затем идёт **;** после чего следуют **id** купленных товаров (если такие имеются), разделённые запятой. Например, **1,2,3,4;** или **1,2,3,4;5,6**.\n",
    "\n",
    "Гарантируется, что среди **id** купленных товаров все различные.\n",
    "\n",
    "### Важно:\n",
    "\n",
    "- Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "\n",
    "- Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    " \n",
    "- Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "\n",
    "- Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и **k** в **recall@k / precision@k**.\n",
    "\n",
    "### Задание\n",
    "\n",
    "1.На обучении постройте частоты появления **id** в просмотренных и в купленных (**id** может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "\n",
    "2.Реализуйте два алгоритма рекомендаций:\n",
    "\n",
    "- сортировка просмотренных **id** по популярности (частота появления в просмотренных),\n",
    "\n",
    "- сортировка просмотренных **id** по покупаемости (частота появления в покупках).\n",
    "\n",
    "3.Для данных алгоритмов выпишите через пробел **AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5** на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "### Дополнительные вопросы\n",
    "\n",
    "1.Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров **recall@k** меняется. Подумайте, как оценить минимальное и максимальное значение **recall@k** в зависимости от правила сортировки.\n",
    "\n",
    "2.Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sessions_train = 'coursera_sessions_train.txt'\n",
    "file_sessions_test = 'coursera_sessions_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMN_NAME_VIEW = 'freq_view'\n",
    "COLUMN_NAME_PURCHASE = 'freq_purchase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,1,2,3,4,5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9,10,11,9,11,12,9,11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16,17,18,19,20,21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   view purchase\n",
       "0           0,1,2,3,4,5      NaN\n",
       "1  9,10,11,9,11,12,9,11      NaN\n",
       "2     16,17,18,19,20,21      NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(file_sessions_train, sep=';', names=['view', 'purchase'])\n",
    "test_data = pd.read_csv(file_sessions_test, sep=';', names=['view', 'purchase'])\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sessions(data):\n",
    "    data_freq = pd.DataFrame(columns=[COLUMN_NAME_VIEW, COLUMN_NAME_PURCHASE])\n",
    "    \n",
    "    for row in data.iterrows():\n",
    "        view_items = row[1]['view'].split(',')\n",
    "        purchase_items = []\n",
    "        if pd.isnull(row[1]['purchase']) == False:\n",
    "            purchase_items = row[1]['purchase'].split(',')\n",
    "        \n",
    "        for item in view_items:\n",
    "            if item in data_freq.index:\n",
    "                data_freq.loc[item, COLUMN_NAME_VIEW] += 1\n",
    "            else:\n",
    "                data_freq = data_freq.append(pd.Series({COLUMN_NAME_VIEW:0, COLUMN_NAME_PURCHASE:0}, name=item))\n",
    "                \n",
    "        for item in purchase_items:\n",
    "            if item in data_freq.index:\n",
    "                data_freq.loc[item, COLUMN_NAME_PURCHASE] += 1\n",
    "            else:\n",
    "                data_freq = data_freq.append(pd.Series({COLUMN_NAME_VIEW:0, COLUMN_NAME_PURCHASE:0}, name=item))  \n",
    "                \n",
    "    return data_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 48s, sys: 1 s, total: 11min 49s\n",
      "Wall time: 11min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "freq_train = read_sessions(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Возвращает список id без повторений\n",
    "def get_ids(ids):\n",
    "    new_ids = []\n",
    "    for id_ in ids:\n",
    "        if id_ not in new_ids:\n",
    "            new_ids.append(id_)\n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Возвращает отсортированный список ids.\n",
    "# Сортировка по просмотренным товарам (sort_by = 'freq_view') \n",
    "# Сортировка по купленным товарам (sort_by='freq_purchase)\n",
    "# Сортируется по таблице data_freq.\n",
    "def get_recommendations(ids, data_freq, sort_by, k):\n",
    "    ids = get_ids(ids)\n",
    "    recomendations_count = min(k, len(ids))\n",
    "    # таблица со значениями id и значениями ранга\n",
    "    freq_ids = pd.DataFrame(columns=['order', COLUMN_NAME_VIEW, COLUMN_NAME_PURCHASE])\n",
    "    \n",
    "    order = 0\n",
    "    row = pd.Series()\n",
    "    \n",
    "    for id_ in ids:\n",
    "        if id_ in data_freq.index:\n",
    "            row = data_freq.loc[id_, :].append(pd.Series({'order': order}))\n",
    "        else:\n",
    "            row = pd.Series({COLUMN_NAME_VIEW: 0, COLUMN_NAME_PURCHASE: 0, 'order': order})\n",
    "        \n",
    "        row.name = id_\n",
    "        freq_ids = freq_ids.append(row)\n",
    "        order += 1\n",
    "\n",
    "    freq_ids.sort_values(by=[sort_by, 'order'], ascending=[False, True], inplace=True)\n",
    "    return freq_ids.index[:recomendations_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_metrics(data, k, data_freq, sort_by):\n",
    "    recall = np.array([])\n",
    "    precision = np.array([])\n",
    "    \n",
    "    data = data.dropna()\n",
    "    for row in data.iterrows():\n",
    "        view_items = row[1]['view'].split(',')\n",
    "        purchase_items = row[1]['purchase'].split(',')\n",
    "        \n",
    "        recomendations = get_recommendations(view_items, data_freq, sort_by, k)\n",
    "        purchase_from_recomendations = set.intersection(set(recomendations), set(purchase_items))\n",
    "\n",
    "        precision = np.append(precision, float(len(purchase_from_recomendations))/k)\n",
    "        recall = np.append(recall, float(len(purchase_from_recomendations))/len(purchase_items)) \n",
    "        \n",
    "    return (np.mean(recall), np.mean(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Итоговая таблица результатов\n",
    "columns = ['recommendations', 'sample', 'by_view_popularity', 'by_purchase_popularity']\n",
    "result_recall = pd.DataFrame(columns=columns)\n",
    "result_precision = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сортировка по частототе появления в просмотренных (обучающая выборка):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 80 ms, total: 1min 57s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recall_1, precision_1 = get_metrics(data=train_data, k=1, data_freq=freq_train, sort_by=COLUMN_NAME_VIEW)\n",
    "recall_5, precision_5 = get_metrics(data=train_data, k=5, data_freq=freq_train, sort_by=COLUMN_NAME_VIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_recall = result_recall.append({'recommendations':1, 'by_view_popularity':recall_1, \n",
    "                                      'sample': 'train'}, ignore_index=True)\n",
    "result_precision = result_precision.append({'recommendations':1, 'by_view_popularity':precision_1, \n",
    "                                            'sample': 'train'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_recall = result_recall.append({'recommendations':5, 'by_view_popularity':recall_5, \n",
    "                                      'sample': 'train'}, ignore_index=True)\n",
    "result_precision = result_precision.append({'recommendations':5, 'by_view_popularity':precision_5, \n",
    "                                            'sample': 'train'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answers = [recall_1, precision_1, recall_5, precision_5]\n",
    "with open(\"views_popularity_train.txt\", \"w\") as fout:\n",
    "    fout.write(\" \".join([\"%.2f\"%num for num in answers]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сортировка по частоте появления в покупках (обучающая выборка):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 116 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recall_1, precision_1 = get_metrics(data=train_data, k=1, data_freq=freq_train, sort_by=COLUMN_NAME_PURCHASE)\n",
    "recall_5, precision_5 = get_metrics(data=train_data, k=5, data_freq=freq_train, sort_by=COLUMN_NAME_PURCHASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = result_recall[(result_recall['recommendations']==1)&(result_recall['sample']=='train')].index\n",
    "result_recall.loc[index, 'by_purchase_popularity'] = recall_1\n",
    "\n",
    "index = result_recall[(result_recall['recommendations']==5)&(result_recall['sample']=='train')].index\n",
    "result_recall.loc[index, 'by_purchase_popularity'] = recall_5\n",
    "\n",
    "index = result_precision[(result_precision['recommendations']==1)&(result_precision['sample']=='train')].index\n",
    "result_precision.loc[index, 'by_purchase_popularity'] = precision_1\n",
    "\n",
    "index = result_precision[(result_precision['recommendations']==5)&(result_precision['sample']=='train')].index\n",
    "result_precision.loc[index, 'by_purchase_popularity'] = precision_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = [recall_1, precision_1, recall_5, precision_5]\n",
    "with open(\"purchases_popularity_train.txt\", \"w\") as fout:\n",
    "    fout.write(\" \".join([\"%.2f\"%num for num in answers]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Сортировка по частототе появления в просмотренных (тестовая выборка):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 128 ms, total: 2min 6s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recall_1, precision_1 = get_metrics(data=test_data, k=1, data_freq=freq_train, sort_by=COLUMN_NAME_VIEW)\n",
    "recall_5, precision_5 = get_metrics(data=test_data, k=5, data_freq=freq_train, sort_by=COLUMN_NAME_VIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_recall = result_recall.append({'recommendations':1, 'by_view_popularity':recall_1, \n",
    "                                      'sample': 'test'}, ignore_index=True)\n",
    "result_precision = result_precision.append({'recommendations':1, 'by_view_popularity':precision_1, \n",
    "                                            'sample': 'test'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_recall = result_recall.append({'recommendations':5, 'by_view_popularity':recall_5, \n",
    "                                      'sample': 'test'}, ignore_index=True)\n",
    "result_precision = result_precision.append({'recommendations':5, 'by_view_popularity':precision_5, \n",
    "                                            'sample': 'test'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = [recall_1, precision_1, recall_5, precision_5]\n",
    "with open(\"views_popularity_test.txt\", \"w\") as fout:\n",
    "    fout.write(\" \".join([\"%.2f\"%num for num in answers]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сортировка по частоте появления в покупках (тестовая выборка):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 136 ms, total: 2min 11s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recall_1, precision_1 = get_metrics(data=test_data, k=1, data_freq=freq_train, sort_by=COLUMN_NAME_PURCHASE)\n",
    "recall_5, precision_5 = get_metrics(data=test_data, k=5, data_freq=freq_train, sort_by=COLUMN_NAME_PURCHASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = result_recall[(result_recall['recommendations']==1)&(result_recall['sample']=='test')].index\n",
    "result_recall.loc[index, 'by_purchase_popularity'] = recall_1\n",
    "\n",
    "index = result_recall[(result_recall['recommendations']==5)&(result_recall['sample']=='test')].index\n",
    "result_recall.loc[index, 'by_purchase_popularity'] = recall_5\n",
    "\n",
    "index = result_precision[(result_precision['recommendations']==1)&(result_precision['sample']=='test')].index\n",
    "result_precision.loc[index, 'by_purchase_popularity'] = precision_1\n",
    "\n",
    "index = result_precision[(result_precision['recommendations']==5)&(result_precision['sample']=='test')].index\n",
    "result_precision.loc[index, 'by_purchase_popularity'] = precision_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = [recall_1, precision_1, recall_5, precision_5]\n",
    "with open(\"purchases_popularity_test.txt\", \"w\") as fout:\n",
    "    fout.write(\" \".join([\"%.2f\"%num for num in answers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendations</th>\n",
       "      <th>sample</th>\n",
       "      <th>by_view_popularity</th>\n",
       "      <th>by_purchase_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.442634</td>\n",
       "      <td>0.689558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.824692</td>\n",
       "      <td>0.926501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.418447</td>\n",
       "      <td>0.460152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.800734</td>\n",
       "      <td>0.820142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendations sample  by_view_popularity  by_purchase_popularity\n",
       "0              1.0  train            0.442634                0.689558\n",
       "1              5.0  train            0.824692                0.926501\n",
       "2              1.0   test            0.418447                0.460152\n",
       "3              5.0   test            0.800734                0.820142"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendations</th>\n",
       "      <th>sample</th>\n",
       "      <th>by_view_popularity</th>\n",
       "      <th>by_purchase_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.212528</td>\n",
       "      <td>0.252716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.482401</td>\n",
       "      <td>0.527422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.203984</td>\n",
       "      <td>0.210095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendations sample  by_view_popularity  by_purchase_popularity\n",
       "0              1.0  train            0.512195                0.804878\n",
       "1              5.0  train            0.212528                0.252716\n",
       "2              1.0   test            0.482401                0.527422\n",
       "3              5.0   test            0.203984                0.210095"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
